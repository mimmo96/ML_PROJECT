import itertools
import numpy as np
import Matrix_io
import neural_network
def cv_k_fold(vector_alfa, vector_learning_rate, vector_lambda, vectors_units, training_set, test_set, batch_array, epochs,function_hidden,function_output, type_weight,type_problem, k_fold = 5):
    #sistemare questo paramentro:##############################################################################################################
    num_training = 0
    ############################################################################################################################################
    trials_per_model = 5
    #divide dataset into K distinct and equal D_1, ..., D_K
    size_validation = training_set.input().shape[0] // 5
    grid = list(itertools.product(vectors_units, vector_alfa, vector_lambda, vector_learning_rate, batch_array, function_hidden, function_output, type_weight))
    top_NN = np.empty(50, tuple) 
    for hyperparameter in grid:
        for k in range(k_fold):
            #cointain K models generated by k partition of TR
            NN_k_fold = np.empty(k_fold, tuple)
            if k == k_fold-1:
                last_set = True
            else:
                last_set = False

            training_k, validation_k = training_set.create_fold(k*size_validation, (k+1)*size_validation, last_set)
            
            #for each model, train "trials_for_model" times with different initialization weights
            NN_trials = np.empty(trials_per_model, neural_network.neural_network)
            for i in range(trials_per_model):
                NN_trials[i] = neural_network.neural_network(hyperparameter[0], hyperparameter[1], hyperparameter[2], hyperparameter[3], (np.size(hyperparameter[0])-1), function_hidden, function_output, type_weight, type_problem)
                NN_trials[i].trainig(training_k, validation_k, hyperparameter[4], epochs, num_training)
            #NN_k_fold[k] = tuple (neaural network, mean_error, dev_standard)
            NN_k_fold[k] = mean_NN(NN_trials, validation_k)
        ########################################################################################    
        best_NN_k_fold = mean_NN(NN_trials, validation_k) #STESSO MODO????????????????????????????????
        ##################################################################################
        if k_is_in_top(top_NN, best_NN_k_fold):
            top_NN.append(best_NN_k_fold)
    
    #retraining with early stopping
    #
    #           write here
    #
    #   
    return top_NN



def mean_NN(array_of_NN, validation_k):
    mean_error = 0
    mean_accuracy = 0
    for NN in array_of_NN:
        accuracy, error = NN.validation(validation_k, penalty_term = 0)
        mean_error += error 
        mean_accuracy += accuracy
    mean_error /= np.size(array_of_NN)
    mean_accuracy /= np.size(array_of_NN)
